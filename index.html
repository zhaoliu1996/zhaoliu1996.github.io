<!DOCTYPE html>
<html>
<head>
  <meta content="text/html;charset=utf-8" http-equiv="Content-Type">
  <meta content="utf-8" http-equiv="encoding">
  <meta name="description" content="MS student at Stanford, research assistant at Stanford AI Lab, computer vision at Tesla."/>
  <title>Vincent Sunn Chen</title>
  <link href="https://fonts.googleapis.com/css?family=Lato:300|Open+Sans" rel="stylesheet">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.8/css/brands.css" integrity="sha384-IiIL1/ODJBRTrDTFk/pW8j0DUI5/z9m1KYsTm/RjZTNV8RHLGZXkUDwgRRbbQ+Jh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.8/css/fontawesome.css" integrity="sha384-q3jl8XQu1OpdLgGFvNRnPdj5VIlCvgsDQTQB6owSOHWlAurxul7f+JpUOVdAiJ5P" crossorigin="anonymous">
  <link href="main.min.css" rel="stylesheet" />
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/favicon.ico" type="image/x-icon">
</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-96755925-1', 'auto');
  ga('send', 'pageview');

</script>

<body class="container">
  <!-- <div class="container"> -->
    <div class='header'>
      <a href="http://twitter.com/vincentsunnchen"><i class='fab fa-twitter'></i> vincentsunnchen</a>
      <a href="http://vincentsc.com/blog">/blog</a>
      <a href="https://github.com/vincentschen"><i class='fab fa-github'></i> vincentschen</a> </a>
    </div>

    <img src="head.jpg">

    <h1>vincent sunn chen</h1>
    <div class='email'> vincentsc [at] cs [dot] stanford [dot] edu</div>

    <div>
      <p>I'm a MS/BS student at Stanford with a concentration in machine learning and a minor in creative writing.
        I'm interested in <a href="http://dawn.cs.stanford.edu/2017/07/16/weak-supervision/">shaping datasets</a> to make machine deep learning more accesible in domains like computer vision and medical imaging.
      </p>

      <p>I'm currently a research assistant in the Stanford AI Lab with <a href="https://cs.stanford.edu/people/chrismre/">Chris Ré</a>'s group.
        Most recently, I've been training neural networks on the <a href="https://www.tesla.com/autopilot">Autopilot vision team at Tesla</a>.
        In the past, I worked at <a href="https://siftscience.com/">Sift Science</a> to fight fraud with machine learning, <a href="https://www.xbox.com/">Xbox</a> to build VR experiences, and <a href="https://emguidance.com/">EMGuidance</a> to build point-of-care healthcare tools.
        At Stanford, I had a lot of fun <a href="https://www.stanforddaily.com/treehacks-2016/">co-directing</a> <a href="https://www.treehacks.com/">TreeHacks</a>, Stanford's largest intercollegiate hackathon.</a>
      </p>

      <p>I also love <a href="https://www.goodreads.com/user/show/45853018-vincent-chen">reading</a>, <a href="https://blog.ycombinator.com/category/paths/">writing</a>, and <a href="https://www.flickr.com/photos/vincentschen/">photography</a>!</p>
    </div>
    <h2>teaching</h2>
    <div class="projects">
      <section>
        <h3>CS231N: Convolutional Neural Networks for Visual Recognition</h3>
        <p><b>Teaching Assistant</b>, <a href="http://cs231n.stanford.edu/">Spring 2018</a></p>
        <p>Hosted office hours, advised student projects, and led discussion sections on <a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds02.pdf">backpropogation</a> and <a href="http://cs231n.stanford.edu/slides/2018/cs231n_2018_ds07.pdf">weak supervision</a>.</p>
      </section>
    </div>

    <h2>projects and papers</h2>
    <div class="projects">
      <section>
        <h3>Automated Training Set Generation for Aortic Valve Classification</h3>
        <p><b>Vincent Chen</b>, Paroma Varma, Madalina Fiterau, James Priest and Christopher Ré. <a href="https://ml4health.github.io/2017/pages/posters.html">Machine Learning for Health (ML4H) Workshop, NIPS, 2017.</a></p>
        <p>Using weak-supervision, we learn probabilistic training labels for aortic valve MRIs.
        <p>[<a href="pdf/nips17_ml4h.pdf">pdf</a>] [<a href="pdf/bav_poster.pdf">poster</a>]</p>
      </section>

      <section>
        <h3>Generating Training Labels for Cardiac Phase-Contrast MRI Images</h3>
        <p><b>Vincent Chen</b>, Paroma Varma, Madalina Fiterau, James Priest and Christopher Ré.
          <a href="https://sites.google.com/view/med-nips-2017/abstracts"> Medical Imaging (MED-NIPS) Workshop, NIPS, 2017.</a></p>
          [<a href="pdf/nips17_med-nips.pdf">pdf</a>]
      </section>

      <section>
        <h3>Predicting Wealth in NYC from FourSquare Check-ins</h3>
        <p><b>Vincent Chen</b>*, Dan Yu*. <a href="http://cs229.stanford.edu/">CS229.</a></p>
        <p>We develop a new method to predict demographics based on FourSquare data by engineering features based on check-ins mapped to U.S. census tracts.
        <p>[<a href="http://vincentsc.com/blog/2018/01/05/predicting-wealth-in-nyc.html">blog</a>] [<a href="pdf/foursquare.pdf">pdf</a>] [<a href="https://github.com/vincentschen/predicting-nyc-demographics">code</a>]</p>
      </section>

      <section>
        <h3>Class-conditional Superresolution with GANs</h3>
        <p><b>Vincent Chen</b>*, Liezl Puzon*, Christina Wadsworth*. <a href="http://cs231n.github.io">CS231N.</a></p>
        <p>We propose several methods to introduce auxiliary, conditional information into generative adversarial networks (GANs) that produce super-resolution results that better tuned to the human eye.</p>
        <p>[<a href="http://cs231n.stanford.edu/reports/2017/pdfs/314.pdf">pdf</a>] [<a href="http://cs231n.stanford.edu/reports/2017/posters/314.pdf">poster</a>] [<a href="https://github.com/vincentschen/cgan-superres">code</a>]</p>
      </section>

      <section>
        <h3>Sequence-to-Sequence Text Summarization</h3>
        <p><b>Vincent Chen</b>*, Liezl Puzon*, Eduardo Torres Montaño*. Advisor: Danqi Chen. <a href="http://web.stanford.edu/class/cs224n/">CS224N.</a></p>
        <p>We implement several approaches for sequence-to-sequence summarization on the CNN/DailyMail dataset using attention mechanisms and pointer networks.</p>
        <p>[<a href="pdf/summarization.pdf">pdf</a>]</p>
      </section>

  <!-- </div> -->
</body>
</html>
